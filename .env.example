# ============================================
# SOCIALIZER (LTSR) Environment Configuration
# ============================================
# Copy this file to .env and fill in your values
# DO NOT commit .env to version control

# --------------------------------------------
# Application Settings
# --------------------------------------------
ENV=development                              # development | staging | production
DEBUG=true
SECRET_KEY=your-secret-key-here-min-32-chars
API_VERSION=v1
ALLOWED_HOSTS=localhost,127.0.0.1

# --------------------------------------------
# Server Configuration
# --------------------------------------------
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
PYTHONPATH=src/backend
FRONTEND_URL=http://localhost:5173
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# --------------------------------------------
# Database (PostgreSQL)
# --------------------------------------------
DATABASE_URL=postgresql+psycopg://ltsr_user:ltsr_password@localhost:5432/ltsr_db
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10
DATABASE_ECHO=false                          # Set to true for SQL query logging

# --------------------------------------------
# Redis (Cache & Task Queue)
# --------------------------------------------
REDIS_URL=redis://localhost:6379/0
REDIS_PASSWORD=                              # Leave empty if no password
REDIS_MAX_CONNECTIONS=50

# --------------------------------------------
# Celery (Background Tasks)
# --------------------------------------------
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
CELERY_TASK_TIME_LIMIT=1800                  # 30 minutes
CELERY_WORKER_PREFETCH_MULTIPLIER=1

# --------------------------------------------
# Instagram / Apify
# --------------------------------------------
APIFY_TOKEN=                                 # Required for instagram-profile-scraper actor

# --------------------------------------------
# Reddit API
# --------------------------------------------
REDDIT_CLIENT_ID=your-reddit-client-id
REDDIT_CLIENT_SECRET=your-reddit-client-secret
REDDIT_USER_AGENT=LTSR/1.0.0 (by /u/yourusername)
REDDIT_USERNAME=your-reddit-username
REDDIT_PASSWORD=your-reddit-password
REDDIT_RATE_LIMIT_CALLS=5000                 # Calls per minute (Enterprise tier)
REDDIT_RATE_LIMIT_PERIOD=60                  # Period in seconds

# --------------------------------------------
# Object Storage (AWS S3 or compatible)
# --------------------------------------------
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_REGION=us-east-1
AWS_S3_BUCKET=ltsr-data-bucket
S3_RAW_PREFIX=raw/
S3_MODELS_PREFIX=models/
S3_EXPORTS_PREFIX=exports/

# --------------------------------------------
# Machine Learning Model
# --------------------------------------------
PRIMARY_MODEL=cardiffnlp/twitter-roberta-base-topic-sentiment-latest
FALLBACK_SERVICE=azure-opinion-mining
CONFIDENCE_THRESHOLD=0.75
SENTIMENT_MIN_CONF=0.55
SENTIMENT_MIN_MARGIN=0.10
FALLBACK_ENABLED=true
MODEL_VERSION=v2025.03.1
BATCH_SIZE=32
ML_TIMEOUT_SECONDS=30                        # Retained for compatibility with Celery task batching
SPACY_MODEL_NAME=en_core_web_lg
SENTIMENT_THRESHOLD=0.5                      # Legacy threshold still used for alerts
SARCASM_THRESHOLD=0.6
TOXICITY_THRESHOLD=0.7
THREAD_ARCHIVE_IDLE_MINUTES=180
AZURE_TEXT_ANALYTICS_ENDPOINT=https://<your-region>.api.cognitive.microsoft.com/
AZURE_TEXT_ANALYTICS_KEY=<your-key>
# Legacy inference values (optional if running historical service)
MODEL_PATH=/data/models/roberta-multitask-v2025.03.1
MODEL_DEVICE=cpu
ML_INFERENCE_URL=http://localhost:8500/predict
MAX_SEQUENCE_LENGTH=512

# --------------------------------------------
# AI Provider Tokens (Legacy)
# --------------------------------------------
HUGGINGFACE_ACCESS_TOKEN=
HF_TOKEN=${HUGGINGFACE_ACCESS_TOKEN}
HUGGINGFACE_HUB_TOKEN=${HF_TOKEN}
HF_HOME=.hf_cache

# ============================================
# LLM Provider Configuration (Phase 2 Automation)
# ============================================

# --------------------------------------------
# OpenAI Configuration
# --------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini                         # gpt-4o-mini | gpt-4o | gpt-4-turbo | gpt-4
# OPENAI_ENDPOINT=https://api.openai.com/v1/chat/completions  # Optional, uses default

# --------------------------------------------
# Anthropic (Claude) Configuration
# --------------------------------------------
# Get your API key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022       # claude-3-5-sonnet-20241022 | claude-3-opus-20240229 | claude-3-haiku-20240307
# ANTHROPIC_ENDPOINT=https://api.anthropic.com/v1/messages  # Optional, uses default

# --------------------------------------------
# Google Gemini Configuration
# --------------------------------------------
# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=AIzaSy-your-gemini-api-key-here
GEMINI_MODEL=gemini-1.5-pro                      # gemini-1.5-pro | gemini-1.5-flash | gemini-1.0-pro
# GEMINI_ENDPOINT=https://generativelanguage.googleapis.com/v1beta/models  # Optional, uses default

# --------------------------------------------
# LLM Cost Monitoring & Budget Control
# --------------------------------------------
# Monthly budget threshold in USD (alerts at 75% and 90%)
COST_ALERT_THRESHOLD=500.0

# Alert notification endpoints (uses existing Slack/SendGrid config below)
ALERT_EMAIL=your-email@example.com

# --------------------------------------------
# LLM Quality Drift Detection
# --------------------------------------------
# Fraction of comments to sample for weekly drift checks (0.05 = 5%)
DRIFT_SAMPLE_RATE=0.05

# Agreement threshold for drift alerts (0.8 = 80% agreement required)
DRIFT_AGREEMENT_THRESHOLD=0.8

# --------------------------------------------
# LLM Analysis Configuration
# --------------------------------------------
# Provider selection (managed by nightly job, do not edit manually)
PROVIDER_PREFERRED=openai

# Confidence and sarcasm thresholds for LLM analysis
LLM_CONFIDENCE_THRESHOLD=0.75
SARCASM_THRESHOLD=0.5

# Upvote weighting cap for aggregation (max upvotes considered)
WEIGHT_CAP=200

# --------------------------------------------
# Authentication (Auth0)
# --------------------------------------------
AUTH0_DOMAIN=your-domain.auth0.com
AUTH0_CLIENT_ID=your-auth0-client-id
AUTH0_CLIENT_SECRET=your-auth0-client-secret
AUTH0_AUDIENCE=https://your-api-identifier
AUTH0_ALGORITHMS=["RS256"]

# --------------------------------------------
# Frontend (Vite) Auth0
# --------------------------------------------
VITE_API_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000/ws
VITE_AUTH0_DOMAIN=your-domain.auth0.com
VITE_AUTH0_CLIENT_ID=your-auth0-client-id
VITE_AUTH0_AUDIENCE=https://your-api-identifier

# --------------------------------------------
# Email (SendGrid)
# --------------------------------------------
SENDGRID_API_KEY=your-sendgrid-api-key
FROM_EMAIL=noreply@yourcompany.com
FROM_NAME=LTSR Alerts

# --------------------------------------------
# Slack Integration
# --------------------------------------------
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
SLACK_CHANNEL=#ltsr-alerts
SLACK_BOT_TOKEN=xoxb-your-bot-token

# --------------------------------------------
# Monitoring & Logging
# --------------------------------------------
# Sentry (Error Tracking)
SENTRY_DSN=https://your-sentry-dsn@sentry.io/project-id
SENTRY_TRACES_SAMPLE_RATE=0.1               # 10% of requests

# Datadog (APM & Metrics)
DATADOG_API_KEY=your-datadog-api-key
DATADOG_APP_KEY=your-datadog-app-key
DATADOG_SERVICE=ltsr
DATADOG_ENV=development

# Logging
LOG_LEVEL=INFO                               # DEBUG | INFO | WARNING | ERROR | CRITICAL
LOG_FORMAT=json                              # json | text

# --------------------------------------------
# Feature Flags
# --------------------------------------------
ENABLE_REAL_TIME_UPDATES=true
ENABLE_WEBSOCKET=true
ENABLE_ALERTS=true
ENABLE_BACKFILL=true
ENABLE_BRIGADE_DETECTION=true
ENABLE_BOT_DETECTION=true

# --------------------------------------------
# Rate Limiting & Throttling
# --------------------------------------------
API_RATE_LIMIT=100                           # Requests per minute per user
API_RATE_LIMIT_PERIOD=60
MAX_CONCURRENT_THREADS=10                    # Max threads analyzed simultaneously

# --------------------------------------------
# Data Retention (Days)
# --------------------------------------------
RAW_COMMENT_RETENTION=30
AGGREGATE_RETENTION=730                      # 2 years
CACHE_TTL_THREAD=900                         # 15 minutes
CACHE_TTL_AGGREGATE=300                      # 5 minutes

# --------------------------------------------
# Security
# --------------------------------------------
AUTHOR_HASH_SALT=change-me
ALLOWED_UPLOAD_EXTENSIONS=.json,.csv
MAX_UPLOAD_SIZE=10485760                     # 10MB in bytes
CORS_MAX_AGE=3600
SESSION_TIMEOUT=3600                         # 1 hour
SECRETS_PROVIDER=env                         # env | aws
SECRETS_PREFIX=                              # Optional env var prefix for secrets (e.g., APP_)
SECRETS_AWS_PREFIX=socializer/               # AWS Secrets Manager path prefix when using aws provider

# --------------------------------------------
# Testing
# --------------------------------------------
TEST_DATABASE_URL=postgresql+psycopg://test:test@localhost:5432/ltsr_test
PYTEST_WORKERS=4
COVERAGE_THRESHOLD=80                        # Minimum coverage percentage

# --------------------------------------------
# Development Tools
# --------------------------------------------
ENABLE_DEBUG_TOOLBAR=true
ENABLE_SWAGGER_UI=true
ENABLE_REDOC=true
FLOWER_PORT=5555                             # Celery Flower monitoring

# --------------------------------------------
# Frontend (React)
# --------------------------------------------
VITE_API_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000
VITE_AUTH0_DOMAIN=${AUTH0_DOMAIN}
VITE_AUTH0_CLIENT_ID=${AUTH0_CLIENT_ID}
VITE_AUTH0_AUDIENCE=${AUTH0_AUDIENCE}

# --------------------------------------------
# Deployment
# --------------------------------------------
DEPLOYMENT_ENV=local                         # local | staging | production
VERSION=1.0.0
BUILD_NUMBER=
GIT_COMMIT=

# --------------------------------------------
# Optional: Weights & Biases (ML Experiment Tracking)
# --------------------------------------------
WANDB_API_KEY=your-wandb-api-key
WANDB_PROJECT=ltsr-sentiment
WANDB_ENTITY=your-wandb-username

# --------------------------------------------
# Optional: Kubernetes Configuration
# --------------------------------------------
K8S_NAMESPACE=ltsr
K8S_SERVICE_NAME=ltsr-backend
K8S_REPLICA_COUNT=3

# --------------------------------------------
# Optional: Custom Configuration
# --------------------------------------------
CUSTOM_CAST_DICTIONARY_URL=https://example.com/cast-dictionary.json
CUSTOM_SLANG_LEXICON_URL=https://example.com/slang-lexicon.json
TIMEZONE=US/Eastern
